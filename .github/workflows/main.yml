name: Main

on:
  push:
    branches: master
  pull_request:
    branches: master

jobs:
  # Tests_pandas:
  #   name: Tests pandas / files
  #   runs-on: ${{ matrix.os }}
  #   env:
  #     BACKENDS: "pandas csv parquet hdf5"
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       os: [ubuntu-latest, windows-latest]
  #       python_version: ["3.7", "3.8"]
  #   steps:
  #   - name: checkout
  #     uses: actions/checkout@v1
  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"
  #   - name: set up environment
  #     run: |
  #       conda activate ibis-dev
  #       ./ci/setup_env.sh "${{ matrix.python_version }}" "$BACKENDS"
  #     shell: bash -l {0}

  #   - name: run tests
  #     run: |
  #       conda activate ibis-dev
  #       PYTEST_BACKENDS=$BACKENDS PYTEST_EXPRESSION="not hdfs" ./ci/run_tests.sh
  #     shell: bash -l {0}

  # Tests_sql:
  #   name: Tests SQL
  #   runs-on: ubuntu-latest
  #   env:
  #     BACKENDS: "postgres mysql sqlite"
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       python_version: ["3.7", "3.8"]
  #   services:
  #     postgres:
  #       image: shajekpivotal/ibis-docker-postgres-9.5
  #       ports:
  #         - 5432:5432
  #       env:
  #         POSTGRES_PASSWORD: ''
  #       options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3
  #     mysql:
  #       image: mariadb:10.4.12
  #       ports:
  #         - 3306:3306
  #       env:
  #         MYSQL_ALLOW_EMPTY_PASSWORD: true
  #         MYSQL_DATABASE: ibis_testing
  #         MYSQL_USER: ibis
  #         MYSQL_PASSWORD: ibis
  #       options: --health-cmd="mysqladmin ping" --health-interval 10s --health-timeout 5s --health-retries 3
  #   steps:
  #   - name: checkout
  #     uses: actions/checkout@v1

  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"

  #   - name: set up environment
  #     run: ./ci/setup_env.sh "${{ matrix.python_version }}" "$BACKENDS"
  #     shell: bash -l {0}

  #   - name: run tests
  #     run: PYTEST_BACKENDS=$BACKENDS PYTEST_EXPRESSION="not udf and not hdfs" ./ci/run_tests.sh
  #     shell: bash -l {0}

  Tests_impala_clickhouse:
    name: Tests Impala / Clickhouse
    runs-on: ubuntu-latest
    container: continuumio/miniconda3
    env:
      BACKENDS: "impala clickhouse"
    strategy:
      fail-fast: false
      matrix:
        python_version: ["3.7", "3.8"]
    services:
      postgres:
        image: shajekpivotal/ibis-docker-postgres-9.5
        ports:
          - 5432:5432
        env:
          POSTGRES_PASSWORD: ''
      impala:
        image: ibisproject/impala:latest
        env:
          PGPASSWORD: postgres
        ports:
          # HDFS
          - 9020:9020
          - 50070:50070
          - 50075:50075
          - 8020:8020
          - 8042:8042
          # Hive
          - 9083:9083

          # Impala
          - 21000:21000
          - 21050:21050
          - 25000:25000
          - 25010:25010
          - 25020:25020
        options: --health-cmd "nc -z 127.0.0.1 21050 && nc -z 127.0.0.1 50070" --health-interval 30s --health-timeout 10s --health-retries 20
      clickhouse:
        # XXX does clickhouse backend require the impala container too?
        image: yandex/clickhouse-server:18.14
        ports:
          - 8123:8123
          - 9000:9000

    steps:
    - name: checkout
      uses: actions/checkout@v1

    - name: check host settings
      run: cat /etc/hosts

    - name: setup conda
      run: |
        conda create --name ibis-dev python=${{ matrix.python_version }} pip
        conda activate ibis-dev
        conda env update --file environment.yml
      shell: bash -l {0}


    - name: set up environment
      env:
        IBIS_TEST_IMPALA_HOST: "impala"
        IBIS_TEST_NN_HOST: "impala"
      run: |
        conda actiavte ibis-dev
        ./ci/setup_env.sh "${{ matrix.python_version }}" "$BACKENDS"
      shell: bash -l {0}

    - name: run tests
      run: |
        conda activate ibis-dev
        PYTEST_BACKENDS=$BACKENDS ./ci/run_tests.sh
      shell: bash -l {0}

  # Tests_omniscidb:
  #   name: Tests OmniSciDB
  #   runs-on: ubuntu-latest
  #   env:
  #     BACKENDS: "omniscidb"
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       python_version: ["3.7"]
  #   services:
  #     omnisci:
  #       image: omnisci/core-os-cpu:v5.2.2
  #       ports:
  #         - 6274:6274
  #         - 6278:6278
  #       volumes:
  #         - omniscidb.conf:/omnisci-storage/omnisci.conf
  #   steps:
  #   - name: checkout
  #     uses: actions/checkout@v1

  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"

  #   - name: set up environment
  #     run: ./ci/setup_env.sh "${{ matrix.python_version }}" "$BACKENDS"
  #     shell: bash -l {0}

  #   - name: run tests
  #     run: PYTEST_BACKENDS=$BACKENDS PYTEST_EXPRESSION="not hdfs" ./ci/run_tests.sh
  #     shell: bash -l {0}

  # Tests_spark:
  #   name: Tests PySpark / Spark
  #   runs-on: ubuntu-latest
  #   env:
  #     BACKENDS: "spark pyspark"
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       python_version: ["3.7", "3.8"]
  #   steps:
  #   - name: checkout
  #     uses: actions/checkout@v1

  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"

  #   - name: set up environment
  #     run: ./ci/setup_env.sh "${{ matrix.python_version }}" "$BACKENDS"
  #     shell: bash -l {0}

  #   - name: run tests
  #     run: PYTEST_BACKENDS=$BACKENDS PYTEST_EXPRESSION="not hdfs" ./ci/run_tests.sh
  #     shell: bash -l {0}


  # Lint_and_benchmarks:
  #   name: Lint and benckmarks
  #   runs-on: ubuntu-latest
  #   steps:

  #   - name: checkout
  #     uses: actions/checkout@v1

  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"

  #   - name: set up environment
  #     run: ./ci/setup_env.sh
  #     shell: bash -l {0}

  #   - name: black
  #     run: black --check .
  #     if: always()
  #     shell: bash -l {0}

  #   - name: mypy
  #     # TODO: mypy has errors that need to be fixed before it can be added
  #     run: mypy --ignore-missing-imports ibis || true
  #     if: always()
  #     shell: bash -l {0}

  #   - name: pydocstyle
  #     # TODO: change match-dir when docstrings are fixed for other backends
  #     run: pydocstyle --match-dir="(ibis|omniscidb)"
  #     if: always()
  #     shell: bash -l {0}

  #   - name: isort
  #     # TODO: isort has errors that need to be fixed before it can be added
  #     run: isort --check-only . || true
  #     if: always()
  #     shell: bash -l {0}

  #   - name: publish feedstock artifact
  #     uses: actions/upload-artifact@master
  #     with:
  #       name: LinuxCondaPackage
  #       path: /tmp/ibis/packages
  #     if: github.event_name == 'push'

  #   - name: benckmark
  #     run: ./ci/benchmark.sh azure "${{ github.sha }}"
  #     if: always()
  #     shell: bash -l {0}

  # Conda_package:
  #   name: Conda package
  #   runs-on: ubuntu-latest
  #   steps:

  #   - name: checkout
  #     uses: actions/checkout@v1

  #   - uses: conda-incubator/setup-miniconda@v1
  #     with:
  #       auto-update-conda: true
  #       python-version: ${{ matrix.python_version }}
  #       activate-environment: "ibis-dev"
  #       environment-file: "environment.yml"

  #   - name: set up environment
  #     run: ./ci/setup_env.sh
  #     shell: bash -l {0}

  #   - name: clone feedstock repo
  #     run: git clone https://github.com/conda-forge/ibis-framework-feedstock /tmp/feedstock
  #     shell: bash -l {0}

  #   - name: update recipe file
  #     run: |
  #       IBIS_PATH=`pwd`
  #       IBIS_VERSION=`python -c "import ibis; print(ibis.__version__)"`

  #       set -x
  #       cd /tmp/feedstock/recipe/

  #       echo "*** Original recipe:"
  #       cat meta.yaml

  #       # remove `{% set version = "X.X.X" %}`
  #       tail -n +2 meta.yaml > meta.tmp && mv meta.tmp meta.yaml

  #       # replace the url and sha256 in the source, by a path
  #       grep -v "^\s*sha256:" meta.yaml > meta.tmp && mv meta.tmp meta.yaml
  #       sed -i "s|url:.*|path: $IBIS_PATH|g" meta.yaml

  #       # set version
  #       sed -i "s/{{ version }}/$IBIS_VERSION/g" meta.yaml

  #       echo "*** Modified recipe:"
  #       cat meta.yaml
  #     shell: bash -l {0}

  #   - name: build recipe
  #     run: conda build -c conda-forge --python 3.7 /tmp/feedstock/recipe
  #     shell: bash -l {0}

  #   - name: deploy recipe package
  #     run: |
  #       mkdir /tmp/packages
  #       cp -r /usr/share/miniconda/envs/ibis-dev/conda-bld/noarch /tmp/packages/noarch
  #       cp -r /usr/share/miniconda/envs/ibis-dev/conda-bld/linux-64 /tmp/packages/linux-64
  #       conda index /tmp/packages
  #     shell: bash -l {0}
